import os  
import argparse  
import logging  
import torch  
import torch.nn as nn  
import torch.optim as optim  
from torch.utils.data import DataLoader  
import pandas as pd  
import numpy as np  
from sklearn.metrics import mean_squared_error  
from sklearn.model_selection import train_test_split  
from scipy.stats import pearsonr  
  
from EHIGN import DTIPredictor  
from graph_constructor import collate_fn  
import dgl  
  
class CustomGraphDataset(object):  
    def __init__(self, data_df, graph_type='Graph_EHIGN_5edges'):  
        self.data_df = data_df  
        self.graph_type = graph_type  
        self.graph_paths = []  
        self.valid_indices = []  
        self._pre_process()  
      
    def _pre_process(self):  
        """é¢„å¤„ç†ï¼šæ£€æŸ¥ DGL æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œè·³è¿‡ç¼ºå¤±çš„æ ·æœ¬"""  
        total_samples = len(self.data_df)  
        skipped_samples = []  
          
        for i, row in self.data_df.iterrows():  
            name = row['name']  
            receptor_path = row['receptor']  
            complex_dir = os.path.dirname(receptor_path)  
            graph_path = os.path.join(complex_dir, f"{self.graph_type}-{name}.dgl")  
              
            if os.path.exists(graph_path):  
                self.graph_paths.append(graph_path)  
                self.valid_indices.append(i)  
            else:  
                skipped_samples.append({  
                    'name': name,  
                    'directory': complex_dir,  
                    'expected_file': f"{self.graph_type}-{name}.dgl"  
                })  
                logging.warning(f"âš ï¸  DGL æ–‡ä»¶ç¼ºå¤± - ç›®å½•: {complex_dir}, æ ·æœ¬: {name}")  
          
        logging.info(f"âœ… æ•°æ®é›†åŠ è½½å®Œæˆ:")  
        logging.info(f"   - æ€»æ ·æœ¬æ•°: {total_samples}")  
        logging.info(f"   - æˆåŠŸåŠ è½½: {len(self.graph_paths)}")  
        logging.info(f"   - è·³è¿‡æ ·æœ¬: {len(skipped_samples)}")  
          
        if skipped_samples:  
            logging.warning(f"\nâš ï¸  ä»¥ä¸‹ {len(skipped_samples)} ä¸ªæ ·æœ¬å›  DGL æ–‡ä»¶ç¼ºå¤±è¢«è·³è¿‡:")  
            for sample in skipped_samples[:5]:  
                logging.warning(f"   - {sample['name']}: {sample['directory']}/{sample['expected_file']}")  
            if len(skipped_samples) > 5:  
                logging.warning(f"   ... è¿˜æœ‰ {len(skipped_samples) - 5} ä¸ªæ ·æœ¬è¢«è·³è¿‡")  
          
        if len(self.graph_paths) == 0:  
            raise ValueError("âŒ é”™è¯¯: æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„ DGL æ–‡ä»¶ï¼è¯·æ£€æŸ¥å›¾æ„å»ºæ­¥éª¤æ˜¯å¦å®Œæˆã€‚")  
      
    def __getitem__(self, idx):  
        return torch.load(self.graph_paths[idx])  
      
    def __len__(self):  
        return len(self.graph_paths)  
  
def val(model, dataloader, device, return_predictions=False):  
    """  
    éªŒè¯å‡½æ•°  
      
    Args:  
        model: æ¨¡å‹  
        dataloader: æ•°æ®åŠ è½½å™¨  
        device: è®¾å¤‡  
        return_predictions: æ˜¯å¦è¿”å›è¯¦ç»†é¢„æµ‹ç»“æœ  
      
    Returns:  
        å¦‚æœ return_predictions=False: (rmse, pr)  
        å¦‚æœ return_predictions=True: (rmse, pr, predictions, labels)  
    """  
    model.eval()  
    pred_list = []  
    label_list = []  
      
    for data in dataloader:  
        bg, label = data  
        bg, label = bg.to(device), label.to(device)  
          
        with torch.no_grad():  
            pred_lp, pred_pl = model(bg)  
            pred = (pred_lp + pred_pl) / 2  
            pred_list.append(pred.detach().cpu().numpy())  
            label_list.append(label.detach().cpu().numpy())  
      
    pred = np.concatenate(pred_list, axis=0)  
    label = np.concatenate(label_list, axis=0)  
    pr = pearsonr(pred, label)[0]  
    rmse = np.sqrt(mean_squared_error(label, pred))  
      
    model.train()  
      
    if return_predictions:  
        return rmse, pr, pred, label  
    else:  
        return rmse, pr  
  
def main():  
    parser = argparse.ArgumentParser(description="Train/Test DTI binding affinity prediction model")  
      
    # æ•°æ®ç›¸å…³å‚æ•°  
    parser.add_argument('--data_csv', type=str, required=True,  
                       help="Path to input CSV file with columns: name,receptor,ligand,pk")  
    parser.add_argument('--mode', type=str, choices=['train', 'test'], default='train',  
                       help="Mode: train (auto-split 9:1) or test (load model and evaluate)")  
    parser.add_argument('--train_ratio', type=float, default=0.9,  
                       help="Training set ratio for auto-split (default: 0.9)")  
    parser.add_argument('--random_seed', type=int, default=42,  
                       help="Random seed for train/valid split")  
    parser.add_argument('--graph_type', type=str, default='Graph_EHIGN_5edges',  
                       help="Graph type for loading DGL files")  
      
    # è®­ç»ƒè¶…å‚æ•°  
    parser.add_argument('--batch_size', type=int, default=96,  
                       help="Batch size for training")  
    parser.add_argument('--epochs', type=int, default=200,  
                       help="Maximum number of training epochs")  
    parser.add_argument('--early_stop_epoch', type=int, default=30,  
                       help="Number of epochs for early stopping patience")  
    parser.add_argument('--learning_rate', type=float, default=1e-4,  
                       help="Learning rate for optimizer")  
    parser.add_argument('--weight_decay', type=float, default=1e-6,  
                       help="Weight decay for optimizer")  
      
    # æ¨¡å‹å‚æ•°  
    parser.add_argument('--node_feat_size', type=int, default=35,  
                       help="Node feature size")  
    parser.add_argument('--edge_feat_size', type=int, default=17,  
                       help="Edge feature size")  
    parser.add_argument('--hidden_feat_size', type=int, default=256,  
                       help="Hidden feature size")  
    parser.add_argument('--layer_num', type=int, default=3,  
                       help="Number of layers in the model")  
      
    # å…¶ä»–å‚æ•°  
    parser.add_argument('--num_workers', type=int, default=8,  
                       help="Number of workers for DataLoader")  
    parser.add_argument('--cuda_device', type=str, default="0",  
                       help="CUDA device ID (e.g., '0' or '0,1')")  
    parser.add_argument('--save_path', type=str, default='best_model.pt',  
                       help="Path to save/load the model")  
    parser.add_argument('--log_file', type=str, default=None,  
                       help="Path to save training log file")  
    parser.add_argument('--output_csv', type=str, default=None,  
                       help="Path to save prediction results CSV (test mode only)")  
      
    args = parser.parse_args()  
      
    # é…ç½®æ—¥å¿—ç³»ç»Ÿ  
    if args.log_file:  
        logging.basicConfig(  
            level=logging.INFO,  
            format='%(asctime)s - %(levelname)s - %(message)s',  
            datefmt='%Y-%m-%d %H:%M:%S',  
            handlers=[  
                logging.FileHandler(args.log_file, mode='w'),  
                logging.StreamHandler()  
            ]  
        )  
        logging.info(f"ğŸ“ æ—¥å¿—å°†ä¿å­˜åˆ°: {args.log_file}")  
    else:  
        logging.basicConfig(  
            level=logging.INFO,  
            format='%(asctime)s - %(levelname)s - %(message)s',  
            datefmt='%Y-%m-%d %H:%M:%S',  
            handlers=[logging.StreamHandler()]  
        )  
      
    # è®¾ç½® CUDA è®¾å¤‡  
    os.environ['CUDA_VISIBLE_DEVICES'] = args.cuda_device  
      
    # è¯»å– CSV æ–‡ä»¶  
    df = pd.read_csv(args.data_csv)  
    required_columns = ['name', 'receptor', 'ligand', 'pk']  
    if not all(col in df.columns for col in required_columns):  
        # å°è¯• pK (å¤§å†™K)  
        if 'pK' in df.columns:  
            df = df.rename(columns={'pK': 'pk'})  
        else:  
            raise ValueError(f"CSV must contain columns: {required_columns} (or 'pK' instead of 'pk')")  
      
    logging.info(f"ğŸ“‚ è¯»å– CSV æ–‡ä»¶: {args.data_csv}")  
    logging.info(f"   - CSV ä¸­æ€»æ ·æœ¬æ•°: {len(df)}")  
      
    if args.mode == 'train':  
        # è®­ç»ƒæ¨¡å¼ï¼šéšæœºåˆ†å‰²ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†  
        train_df, valid_df = train_test_split(  
            df,  
            train_size=args.train_ratio,  
            random_state=args.random_seed,  
            shuffle=True  
        )  
        logging.info(f"\nğŸ”„ è®­ç»ƒæ¨¡å¼: è‡ªåŠ¨åˆ†å‰²æ•°æ®é›† ({args.train_ratio*100:.0f}% è®­ç»ƒ / {(1-args.train_ratio)*100:.0f}% éªŒè¯)")  
        logging.info(f"   - è®­ç»ƒé›† CSV æ ·æœ¬æ•°: {len(train_df)}")  
        logging.info(f"   - éªŒè¯é›† CSV æ ·æœ¬æ•°: {len(valid_df)}")  
    else:  
        # æµ‹è¯•æ¨¡å¼ï¼šä½¿ç”¨å…¨éƒ¨æ•°æ®  
        train_df = df  
        valid_df = df  
        logging.info(f"\nğŸ§ª æµ‹è¯•æ¨¡å¼: ä½¿ç”¨å…¨éƒ¨æ•°æ®è¿›è¡Œè¯„ä¼°")  
        logging.info(f"   - æ•°æ®é›† CSV æ ·æœ¬æ•°: {len(df)}")  
      
    # åˆ›å»ºæ•°æ®é›†  
    logging.info(f"\nğŸ” æ£€æŸ¥è®­ç»ƒé›† DGL æ–‡ä»¶...")  
    train_set = CustomGraphDataset(train_df, graph_type=args.graph_type)  
      
    logging.info(f"\nğŸ” æ£€æŸ¥éªŒè¯é›† DGL æ–‡ä»¶...")  
    valid_set = CustomGraphDataset(valid_df, graph_type=args.graph_type)  
      
    logging.info(f"\nâœ… æœ€ç»ˆæ•°æ®é›†ç»Ÿè®¡:")  
    logging.info(f"   - è®­ç»ƒé›†æœ‰æ•ˆæ ·æœ¬: {len(train_set)}")  
    logging.info(f"   - éªŒè¯é›†æœ‰æ•ˆæ ·æœ¬: {len(valid_set)}")  
      
    # åˆ›å»º DataLoader  
    train_loader = DataLoader(train_set, batch_size=args.batch_size, shuffle=True,  
                             collate_fn=collate_fn, num_workers=args.num_workers)  
    valid_loader = DataLoader(valid_set, batch_size=args.batch_size, shuffle=False,  
                             collate_fn=collate_fn, num_workers=args.num_workers)  
      
    # åˆå§‹åŒ–æ¨¡å‹  
    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')  
    model = DTIPredictor(node_feat_size=args.node_feat_size,  
                        edge_feat_size=args.edge_feat_size,  
                        hidden_feat_size=args.hidden_feat_size,  
                        layer_num=args.layer_num).to(device)  
      
    # ========== å…³é”®ä¿®æ”¹ï¼šåŒºåˆ†è®­ç»ƒå’Œæµ‹è¯•æ¨¡å¼ ==========  
    if args.mode == 'test':  
        # æµ‹è¯•æ¨¡å¼ï¼šåŠ è½½æ¨¡å‹å¹¶è¯„ä¼°  
        logging.info(f"\nğŸ“¥ æµ‹è¯•æ¨¡å¼ï¼šåŠ è½½æ¨¡å‹æƒé‡: {args.save_path}")  
        if not os.path.exists(args.save_path):  
            raise FileNotFoundError(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {args.save_path}")  
          
        model.load_state_dict(torch.load(args.save_path))  
        logging.info("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ!")  
          
        # è¿›è¡Œè¯„ä¼°å¹¶è·å–è¯¦ç»†é¢„æµ‹ç»“æœ  
        logging.info(f"\nğŸ§ª å¼€å§‹æµ‹è¯•è¯„ä¼°...")  
        test_rmse, test_pr, predictions, labels = val(model, valid_loader, device, return_predictions=True)  
        logging.info(f"\nğŸ‰ æµ‹è¯•ç»“æœ: RMSE={test_rmse:.4f}, Pearson={test_pr:.4f}")  
          
        # ä¿å­˜é¢„æµ‹ç»“æœåˆ° CSV  
        if args.output_csv is None:  
            # é»˜è®¤è¾“å‡ºæ–‡ä»¶å  
            csv_dir = os.path.dirname(args.data_csv)  
            csv_basename = os.path.splitext(os.path.basename(args.data_csv))[0]  
            args.output_csv = os.path.join(csv_dir, f"{csv_basename}_predictions.csv")  
          
        # åˆ›å»ºé¢„æµ‹ç»“æœ DataFrame  
        # è·å–æœ‰æ•ˆæ ·æœ¬çš„ä¿¡æ¯  
        valid_indices = valid_set.valid_indices  
        result_df = valid_df.iloc[valid_indices].copy()  
        result_df['predicted_pK'] = predictions.flatten()  
        result_df['true_pK'] = labels.flatten()  
        result_df['error'] = result_df['predicted_pK'] - result_df['true_pK']  
        result_df['absolute_error'] = np.abs(result_df['error'])  
          
        # ä¿å­˜åˆ° CSV  
        result_df.to_csv(args.output_csv, index=False)  
        logging.info(f"ğŸ“Š é¢„æµ‹ç»“æœå·²ä¿å­˜åˆ°: {args.output_csv}")  
        logging.info(f"   - åŒ…å«åˆ—: {list(result_df.columns)}")  
          
    else:  
        # è®­ç»ƒæ¨¡å¼ï¼šæ‰§è¡Œè®­ç»ƒå¾ªç¯  
        optimizer = optim.Adam(model.parameters(), lr=args.learning_rate,  
                              weight_decay=args.weight_decay)  
        criterion = nn.MSELoss()  
          
        logging.info(f"\nğŸš€ å¼€å§‹è®­ç»ƒ...")  
        logging.info(f"   - å­¦ä¹ ç‡: {args.learning_rate}")  
        logging.info(f"   - æ‰¹æ¬¡å¤§å°: {args.batch_size}")  
        logging.info(f"   - æœ€å¤§è½®æ•°: {args.epochs}")  
        logging.info(f"   - æ—©åœè€å¿ƒå€¼: {args.early_stop_epoch}")  
          
        # è®­ç»ƒå¾ªç¯  
        best_valid_rmse = float('inf')  
        patience_counter = 0  
          
        model.train()  
        for epoch in range(args.epochs):  
            # è®­ç»ƒé˜¶æ®µ  
            epoch_loss = 0.0  
            for data in train_loader:  
                bg, label = data  
                bg, label = bg.to(device), label.to(device)  
                  
                pred_lp, pred_pl = model(bg)  
                loss = (criterion(pred_lp, label) + criterion(pred_pl, label) +  
                       criterion(pred_lp, pred_pl)) / 3  
                  
                optimizer.zero_grad()  
                loss.backward()  
                optimizer.step()  
                  
                epoch_loss += loss.item() * label.size(0)  
              
            epoch_loss = epoch_loss / len(train_set)  
            epoch_rmse = np.sqrt(epoch_loss)  
              
            # éªŒè¯é˜¶æ®µ  
            valid_rmse, valid_pr = val(model, valid_loader, device)  
              
            logging.info(f"Epoch {epoch}: train_loss={epoch_loss:.4f}, train_rmse={epoch_rmse:.4f}, "  
                        f"valid_rmse={valid_rmse:.4f}, valid_pr={valid_pr:.4f}")  
              
            # ä¿å­˜æœ€ä½³æ¨¡å‹  
            if valid_rmse < best_valid_rmse:  
                best_valid_rmse = valid_rmse  
                patience_counter = 0  
                torch.save(model.state_dict(), args.save_path)  
                logging.info(f"ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹ (valid_rmse={valid_rmse:.4f})")  
            else:  
                patience_counter += 1  
                if patience_counter >= args.early_stop_epoch:  
                    logging.info(f"â¹ï¸  Early stopping at epoch {epoch}")  
                    break  
          
        # åŠ è½½æœ€ä½³æ¨¡å‹å¹¶æœ€ç»ˆéªŒè¯  
        logging.info(f"\nğŸ“Š åŠ è½½æœ€ä½³æ¨¡å‹è¿›è¡Œæœ€ç»ˆè¯„ä¼°...")  
        model.load_state_dict(torch.load(args.save_path))  
        final_valid_rmse, final_valid_pr = val(model, valid_loader, device)  
        logging.info(f"\nğŸ‰ æœ€ç»ˆéªŒè¯ç»“æœ: RMSE={final_valid_rmse:.4f}, Pearson={final_valid_pr:.4f}")  
  
if __name__ == '__main__':  
    main()

