#!/usr/bin/env python  
"""  
æ•´åˆè„šæœ¬ï¼šè‡ªåŠ¨æ‰§è¡Œé¢„å¤„ç†ã€å›¾æ„å»ºå’Œè®­ç»ƒ/æµ‹è¯•çš„å®Œæ•´æµç¨‹  
"""  
  
import os  
import sys  
import argparse  
import subprocess  
import pandas as pd  
from pathlib import Path  
  
  
def run_command(cmd, description):  
    """æ‰§è¡Œå‘½ä»¤å¹¶å¤„ç†é”™è¯¯"""  
    print(f"\n{'='*80}")  
    print(f"Step: {description}")  
    print(f"Command: {' '.join(cmd)}")  
    print(f"{'='*80}\n")  
      
    result = subprocess.run(cmd, capture_output=False, text=True)  
      
    if result.returncode != 0:  
        print(f"\nâŒ Error: {description} failed with return code {result.returncode}")  
        sys.exit(1)  
      
    print(f"\nâœ… {description} completed successfully\n")  
  
  
def main():  
    parser = argparse.ArgumentParser(  
        description="ç«¯åˆ°ç«¯æµç¨‹ï¼šé¢„å¤„ç† â†’ å›¾æ„å»º â†’ è®­ç»ƒ/æµ‹è¯•",  
        formatter_class=argparse.RawDescriptionHelpFormatter,  
        epilog="""  
ç¤ºä¾‹ç”¨æ³•:  
  # å®Œæ•´è®­ç»ƒæµç¨‹  
  python run_pipeline.py --data_csv data.csv --mode train  
    
  # åªåšé¢„å¤„ç†å’Œå›¾æ„å»º  
  python run_pipeline.py --data_csv data.csv --skip_train  
    
  # æµ‹è¯•æ¨¡å¼  
  python run_pipeline.py --data_csv data.csv --mode test  
    
  # è·³è¿‡é¢„å¤„ç†  
  python run_pipeline.py --data_csv data.csv --mode train --skip_preprocess  
    
  # è·³è¿‡å›¾æ„å»º  
  python run_pipeline.py --data_csv data.csv --mode train --skip_graph  
        """  
    )  
      
    # === å¿…éœ€å‚æ•° ===  
    parser.add_argument('--data_csv', type=str, required=True,  
                       help="è¾“å…¥ CSV æ–‡ä»¶è·¯å¾„ (æ ¼å¼: name,receptor,ligand,pk)")  
    parser.add_argument('--mode', type=str, choices=['train', 'test'], default='train',  
                       help="è¿è¡Œæ¨¡å¼: train (è®­ç»ƒ) æˆ– test (æµ‹è¯•)")  
      
    # === æµç¨‹æ§åˆ¶å‚æ•° ===  
    parser.add_argument('--skip_preprocess', action='store_true',  
                       help="è·³è¿‡é¢„å¤„ç†æ­¥éª¤ï¼ˆå‡è®¾ .rdkit æ–‡ä»¶å·²å­˜åœ¨ï¼‰")  
    parser.add_argument('--skip_graph', action='store_true',  
                       help="è·³è¿‡å›¾æ„å»ºæ­¥éª¤ï¼ˆå‡è®¾ .dgl æ–‡ä»¶å·²å­˜åœ¨ï¼‰")  
    parser.add_argument('--skip_train', action='store_true',  
                       help="è·³è¿‡è®­ç»ƒ/æµ‹è¯•æ­¥éª¤ï¼Œåªæ‰§è¡Œé¢„å¤„ç†å’Œå›¾æ„å»º")  
      
    # === é¢„å¤„ç†å‚æ•° (batch_custom_preprocess.py) ===  
    parser.add_argument('--distance', type=float, default=5.0,  
                       help="å£è¢‹æå–è·ç¦» (Ã…) [é»˜è®¤: 5.0]")  
    parser.add_argument('--preprocess_n_jobs', type=int, default=4,  
                       help="é¢„å¤„ç†å¹¶è¡Œè¿›ç¨‹æ•° [é»˜è®¤: 4]")  
    parser.add_argument('--preprocess_batch_size', type=int, default=1000,  
                       help="é¢„å¤„ç†æ‰¹æ¬¡å¤§å° [é»˜è®¤: 1000]")  
    parser.add_argument('--preprocess_timeout', type=int, default=300,  
                       help="å•ä¸ªå¤åˆç‰©å¤„ç†è¶…æ—¶æ—¶é—´(ç§’) [é»˜è®¤: 300]")  
      
    # === å›¾æ„å»ºå‚æ•° (graph_constructor.py) ===  
    parser.add_argument('--graph_type', type=str, default='Graph_EHIGN_5edges',  
                       help="å›¾ç±»å‹å‰ç¼€ [é»˜è®¤: Graph_EHIGN_5edges]")  
    parser.add_argument('--dis_threshold', type=float, default=5.0,  
                       help="ç›¸äº’ä½œç”¨è·ç¦»é˜ˆå€¼ (Ã…) [é»˜è®¤: 5.0]")  
    parser.add_argument('--graph_num_process', type=int, default=28,  
                       help="å›¾æ„å»ºå¹¶è¡Œè¿›ç¨‹æ•° [é»˜è®¤: 28]")  
      
    # === è®­ç»ƒå‚æ•° (train.py) ===  
    parser.add_argument('--batch_size', type=int, default=96,  
                       help="è®­ç»ƒæ‰¹æ¬¡å¤§å° [é»˜è®¤: 96]")  
    parser.add_argument('--epochs', type=int, default=200,  
                       help="æœ€å¤§è®­ç»ƒè½®æ•° [é»˜è®¤: 200]")  
    parser.add_argument('--early_stop_epoch', type=int, default=30,  
                       help="æ—©åœè€å¿ƒå€¼ [é»˜è®¤: 30]")  
    parser.add_argument('--learning_rate', type=float, default=1e-4,  
                       help="å­¦ä¹ ç‡ [é»˜è®¤: 1e-4]")  
    parser.add_argument('--weight_decay', type=float, default=1e-6,  
                       help="æƒé‡è¡°å‡ [é»˜è®¤: 1e-6]")  
    parser.add_argument('--train_ratio', type=float, default=0.9,  
                       help="è®­ç»ƒé›†æ¯”ä¾‹ï¼ˆä»…è®­ç»ƒæ¨¡å¼ï¼‰[é»˜è®¤: 0.9]")  
    parser.add_argument('--random_seed', type=int, default=42,  
                       help="éšæœºç§å­ [é»˜è®¤: 42]")  
      
    # === æ¨¡å‹å‚æ•° ===  
    parser.add_argument('--node_feat_size', type=int, default=35,  
                       help="èŠ‚ç‚¹ç‰¹å¾ç»´åº¦ [é»˜è®¤: 35]")  
    parser.add_argument('--edge_feat_size', type=int, default=17,  
                       help="è¾¹ç‰¹å¾ç»´åº¦ [é»˜è®¤: 17]")  
    parser.add_argument('--hidden_feat_size', type=int, default=256,  
                       help="éšè—å±‚ç»´åº¦ [é»˜è®¤: 256]")  
    parser.add_argument('--layer_num', type=int, default=3,  
                       help="GNN å±‚æ•° [é»˜è®¤: 3]")  
      
    # === å…¶ä»–å‚æ•° ===  
    parser.add_argument('--num_workers', type=int, default=8,  
                       help="DataLoader å·¥ä½œè¿›ç¨‹æ•° [é»˜è®¤: 8]")  
    parser.add_argument('--cuda_device', type=str, default="0",  
                       help="CUDA è®¾å¤‡ ID [é»˜è®¤: '0']")  
    parser.add_argument('--save_path', type=str, default='best_model.pt',  
                       help="æ¨¡å‹ä¿å­˜è·¯å¾„ [é»˜è®¤: best_model.pt]")  
      
    args = parser.parse_args()  
      
    # éªŒè¯è¾“å…¥æ–‡ä»¶  
    if not os.path.exists(args.data_csv):  
        print(f"âŒ Error: CSV æ–‡ä»¶ä¸å­˜åœ¨: {args.data_csv}")  
        sys.exit(1)  
      
    # éªŒè¯ CSV æ ¼å¼  
    try:  
        df = pd.read_csv(args.data_csv)  
        required_columns = ['name', 'receptor', 'ligand', 'pk']  
        if not all(col in df.columns for col in required_columns):  
            print(f"âŒ Error: CSV å¿…é¡»åŒ…å«åˆ—: {required_columns}")  
            print(f"   å®é™…åˆ—: {list(df.columns)}")  
            sys.exit(1)  
        print(f"âœ… CSV æ–‡ä»¶éªŒè¯é€šè¿‡: {len(df)} ä¸ªå¤åˆç‰©")  
    except Exception as e:  
        print(f"âŒ Error: æ— æ³•è¯»å– CSV æ–‡ä»¶: {e}")  
        sys.exit(1)  
      
    csv_dir = os.path.dirname(os.path.abspath(args.data_csv))  
    processed_csv = os.path.join(csv_dir, "processed_valid.csv")  
      
    # ========== Step 1: é¢„å¤„ç† ==========  
    if not args.skip_preprocess:  
        preprocess_cmd = [  
            'python', 'batch_custom_preprocess.py',  
            '--csv', args.data_csv,  
            '--distance', str(args.distance),  
            '--n_jobs', str(args.preprocess_n_jobs),  
            '--batch_size', str(args.preprocess_batch_size),  
            '--timeout', str(args.preprocess_timeout)  
        ]  
        run_command(preprocess_cmd, "é¢„å¤„ç† (batch_custom_preprocess.py)")  
          
        # æ£€æŸ¥é¢„å¤„ç†è¾“å‡º  
        if not os.path.exists(processed_csv):  
            print(f"âŒ Error: é¢„å¤„ç†æœªç”Ÿæˆè¾“å‡ºæ–‡ä»¶: {processed_csv}")  
            sys.exit(1)  
    else:  
        print(f"\nâ­ï¸  è·³è¿‡é¢„å¤„ç†æ­¥éª¤")  
        if not os.path.exists(processed_csv):  
            print(f"âš ï¸  Warning: processed_csv ä¸å­˜åœ¨ï¼Œå°†ä½¿ç”¨åŸå§‹ CSV: {args.data_csv}")  
            processed_csv = args.data_csv  
      
    # ========== Step 2: å›¾æ„å»º ==========  
    if not args.skip_graph:  
        graph_cmd = [  
            'python', 'graph_constructor.py',  
            '--csv_file', processed_csv,  
            '--graph_type', args.graph_type,  
            '--dis_threshold', str(args.dis_threshold),  
            '--num_process', str(args.graph_num_process),  
            '--create'  
        ]  
        run_command(graph_cmd, "å›¾æ„å»º (graph_constructor.py)")  
    else:  
        print(f"\nâ­ï¸  è·³è¿‡å›¾æ„å»ºæ­¥éª¤")  
      
    # ========== Step 3: è®­ç»ƒ/æµ‹è¯• ==========  
    if not args.skip_train:  
        train_cmd = [  
            'python', 'train.py',  
            '--data_csv', processed_csv,  
            '--mode', args.mode,  
            '--graph_type', args.graph_type,  
            '--batch_size', str(args.batch_size),  
            '--epochs', str(args.epochs),  
            '--early_stop_epoch', str(args.early_stop_epoch),  
            '--learning_rate', str(args.learning_rate),  
            '--weight_decay', str(args.weight_decay),  
            '--train_ratio', str(args.train_ratio),  
            '--random_seed', str(args.random_seed),  
            '--node_feat_size', str(args.node_feat_size),  
            '--edge_feat_size', str(args.edge_feat_size),  
            '--hidden_feat_size', str(args.hidden_feat_size),  
            '--layer_num', str(args.layer_num),  
            '--num_workers', str(args.num_workers),  
            '--cuda_device', args.cuda_device,  
            '--save_path', args.save_path  
        ]  
          
        mode_desc = "è®­ç»ƒ" if args.mode == 'train' else "æµ‹è¯•"  
        run_command(train_cmd, f"{mode_desc} (train.py)")  
    else:  
        print(f"\nâ­ï¸  è·³è¿‡è®­ç»ƒ/æµ‹è¯•æ­¥éª¤")  
      
    # ========== å®Œæˆ ==========  
    print(f"\n{'='*80}")  
    print(f"ğŸ‰ å®Œæ•´æµç¨‹æ‰§è¡ŒæˆåŠŸï¼")  
    print(f"{'='*80}")  
    if not args.skip_train:  
        mode_desc = "è®­ç»ƒ" if args.mode == 'train' else "æµ‹è¯•"  
        print(f"æ¨¡å¼: {mode_desc}")  
    print(f"è¾“å…¥ CSV: {args.data_csv}")  
    print(f"å¤„ç†å CSV: {processed_csv}")  
    if args.mode == 'train' and not args.skip_train:  
        print(f"æœ€ä½³æ¨¡å‹: {args.save_path}")  
    print(f"{'='*80}\n")  
  
  
if __name__ == '__main__':  
    main()