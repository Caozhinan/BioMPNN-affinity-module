import os      
import argparse  
import logging  
import torch      
import torch.nn as nn      
import torch.optim as optim      
from torch.utils.data import DataLoader      
import pandas as pd      
import numpy as np      
from sklearn.metrics import mean_squared_error      
from sklearn.model_selection import train_test_split      
from scipy.stats import pearsonr      
      
from EHIGN import DTIPredictor      
from graph_constructor import collate_fn      
import dgl      
      
class CustomGraphDataset(object):      
    def __init__(self, data_df, graph_type='Graph_EHIGN_5edges'):      
        self.data_df = data_df      
        self.graph_type = graph_type      
        self.graph_paths = []  
        self.valid_indices = []  # è®°å½•æœ‰æ•ˆæ ·æœ¬çš„ç´¢å¼•  
        self._pre_process()      
          
    def _pre_process(self):  
        """é¢„å¤„ç†ï¼šæ£€æŸ¥ DGL æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œè·³è¿‡ç¼ºå¤±çš„æ ·æœ¬"""  
        total_samples = len(self.data_df)  
        skipped_samples = []  
          
        for i, row in self.data_df.iterrows():      
            name = row['name']      
            receptor_path = row['receptor']      
            complex_dir = os.path.dirname(receptor_path)      
            graph_path = os.path.join(complex_dir, f"{self.graph_type}-{name}.dgl")      
                  
            if os.path.exists(graph_path):      
                self.graph_paths.append(graph_path)  
                self.valid_indices.append(i)  
            else:  
                skipped_samples.append({  
                    'name': name,  
                    'directory': complex_dir,  
                    'expected_file': f"{self.graph_type}-{name}.dgl"  
                })  
                logging.warning(f"âš ï¸  DGL æ–‡ä»¶ç¼ºå¤± - ç›®å½•: {complex_dir}, æ ·æœ¬: {name}")  
          
        # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯  
        logging.info(f"âœ… æ•°æ®é›†åŠ è½½å®Œæˆ:")  
        logging.info(f"   - æ€»æ ·æœ¬æ•°: {total_samples}")  
        logging.info(f"   - æˆåŠŸåŠ è½½: {len(self.graph_paths)}")  
        logging.info(f"   - è·³è¿‡æ ·æœ¬: {len(skipped_samples)}")  
          
        if skipped_samples:  
            logging.warning(f"\nâš ï¸  ä»¥ä¸‹ {len(skipped_samples)} ä¸ªæ ·æœ¬å›  DGL æ–‡ä»¶ç¼ºå¤±è¢«è·³è¿‡:")  
            for sample in skipped_samples:  
                logging.warning(f"   - {sample['name']}: {sample['directory']}/{sample['expected_file']}")  
          
        if len(self.graph_paths) == 0:  
            raise ValueError("âŒ é”™è¯¯: æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„ DGL æ–‡ä»¶ï¼è¯·æ£€æŸ¥å›¾æ„å»ºæ­¥éª¤æ˜¯å¦å®Œæˆã€‚")  
          
    def __getitem__(self, idx):      
        return torch.load(self.graph_paths[idx])      
          
    def __len__(self):      
        return len(self.graph_paths)      
      
def val(model, dataloader, device):      
    model.eval()      
    pred_list = []      
    label_list = []      
          
    for data in dataloader:      
        bg, label = data      
        bg, label = bg.to(device), label.to(device)      
              
        with torch.no_grad():      
            pred_lp, pred_pl = model(bg)      
            pred = (pred_lp + pred_pl) / 2      
            pred_list.append(pred.detach().cpu().numpy())      
            label_list.append(label.detach().cpu().numpy())      
          
    pred = np.concatenate(pred_list, axis=0)      
    label = np.concatenate(label_list, axis=0)      
    pr = pearsonr(pred, label)[0]      
    rmse = np.sqrt(mean_squared_error(label, pred))      
          
    model.train()      
    return rmse, pr      
      
def main():      
    parser = argparse.ArgumentParser(description="Fine-tune DTI binding affinity prediction model")      
          
    # æ•°æ®ç›¸å…³å‚æ•°      
    parser.add_argument('--data_csv', type=str, required=True,      
                       help="Path to input CSV file with columns: receptor,ligand,name,pK")      
    parser.add_argument('--pretrained_ckpt', type=str, required=True,      
                       help="Path to pretrained checkpoint (.pt file)")      
    parser.add_argument('--mode', type=str, choices=['train', 'test'], default='train',      
                       help="Mode: train (auto-split 9:1) or test (use full dataset)")      
    parser.add_argument('--train_ratio', type=float, default=0.9,      
                       help="Training set ratio for auto-split (default: 0.9)")      
    parser.add_argument('--random_seed', type=int, default=42,      
                       help="Random seed for train/valid split")      
    parser.add_argument('--graph_type', type=str, default='Graph_EHIGN_5edges',      
                       help="Graph type for loading DGL files")      
          
    # å¾®è°ƒè¶…å‚æ•°      
    parser.add_argument('--batch_size', type=int, default=64,      
                       help="Batch size for training")      
    parser.add_argument('--epochs', type=int, default=200,      
                       help="Maximum number of training epochs")      
    parser.add_argument('--early_stop_epoch', type=int, default=20,      
                       help="Number of epochs for early stopping patience")      
    parser.add_argument('--learning_rate', type=float, default=1e-4,      
                       help="Learning rate for optimizer")      
    parser.add_argument('--weight_decay', type=float, default=1e-6,      
                       help="Weight decay for optimizer")      
          
    # æ¨¡å‹å‚æ•°      
    parser.add_argument('--node_feat_size', type=int, default=35,      
                       help="Node feature size")      
    parser.add_argument('--edge_feat_size', type=int, default=17,      
                       help="Edge feature size")      
    parser.add_argument('--hidden_feat_size', type=int, default=256,      
                       help="Hidden feature size")      
    parser.add_argument('--layer_num', type=int, default=3,      
                       help="Number of layers in the model")      
          
    # å…¶ä»–å‚æ•°      
    parser.add_argument('--num_workers', type=int, default=8,      
                       help="Number of workers for DataLoader")      
    parser.add_argument('--cuda_device', type=str, default="0",      
                       help="CUDA device ID (e.g., '0' or '0,1')")      
    parser.add_argument('--save_path', type=str, default='finetuned_model.pt',      
                       help="Path to save the fine-tuned model")  
      
    # æ—¥å¿—å‚æ•°  
    parser.add_argument('--log_file', type=str, default=None,  
                       help="Path to save training log file (default: None, only print to console)")  
          
    args = parser.parse_args()  
      
    # é…ç½®æ—¥å¿—ç³»ç»Ÿ  
    if args.log_file:  
        logging.basicConfig(  
            level=logging.INFO,  
            format='%(asctime)s - %(levelname)s - %(message)s',  
            datefmt='%Y-%m-%d %H:%M:%S',  
            handlers=[  
                logging.FileHandler(args.log_file, mode='w'),  
                logging.StreamHandler()  
            ]  
        )  
        logging.info(f"ğŸ“ æ—¥å¿—å°†ä¿å­˜åˆ°: {args.log_file}")  
    else:  
        logging.basicConfig(  
            level=logging.INFO,  
            format='%(asctime)s - %(levelname)s - %(message)s',  
            datefmt='%Y-%m-%d %H:%M:%S',  
            handlers=[logging.StreamHandler()]  
        )  
          
    # è®¾ç½® CUDA è®¾å¤‡      
    os.environ['CUDA_VISIBLE_DEVICES'] = args.cuda_device      
          
    # è¯»å– CSV æ–‡ä»¶      
    df = pd.read_csv(args.data_csv)      
    required_columns = ['receptor', 'ligand', 'name', 'pk']      
    if not all(col in df.columns for col in required_columns):      
        raise ValueError(f"CSV must contain columns: {required_columns}")      
      
    logging.info(f"ğŸ“‚ è¯»å– CSV æ–‡ä»¶: {args.data_csv}")  
    logging.info(f"   - CSV ä¸­æ€»æ ·æœ¬æ•°: {len(df)}")  
          
    if args.mode == 'train':      
        train_df, valid_df = train_test_split(      
            df,       
            train_size=args.train_ratio,       
            random_state=args.random_seed,      
            shuffle=True      
        )      
        logging.info(f"\nğŸ”„ å¾®è°ƒæ¨¡å¼: è‡ªåŠ¨åˆ†å‰²æ•°æ®é›† ({args.train_ratio*100:.0f}% è®­ç»ƒ / {(1-args.train_ratio)*100:.0f}% éªŒè¯)")      
        logging.info(f"   - è®­ç»ƒé›† CSV æ ·æœ¬æ•°: {len(train_df)}")      
        logging.info(f"   - éªŒè¯é›† CSV æ ·æœ¬æ•°: {len(valid_df)}")      
    else:      
        train_df = df      
        valid_df = df      
        logging.info(f"\nğŸ§ª æµ‹è¯•æ¨¡å¼: ä½¿ç”¨å…¨éƒ¨æ•°æ®")      
        logging.info(f"   - æ•°æ®é›† CSV æ ·æœ¬æ•°: {len(df)}")      
          
    # åˆ›å»ºæ•°æ®é›†ï¼ˆä¼šè‡ªåŠ¨æ£€æµ‹å¹¶è·³è¿‡ç¼ºå¤±çš„ DGL æ–‡ä»¶ï¼‰  
    logging.info(f"\nğŸ” æ£€æŸ¥è®­ç»ƒé›† DGL æ–‡ä»¶...")  
    train_set = CustomGraphDataset(train_df, graph_type=args.graph_type)      
      
    logging.info(f"\nğŸ” æ£€æŸ¥éªŒè¯é›† DGL æ–‡ä»¶...")  
    valid_set = CustomGraphDataset(valid_df, graph_type=args.graph_type)      
          
    logging.info(f"\nâœ… æœ€ç»ˆæ•°æ®é›†ç»Ÿè®¡:")  
    logging.info(f"   - è®­ç»ƒé›†æœ‰æ•ˆæ ·æœ¬: {len(train_set)}")      
    logging.info(f"   - éªŒè¯é›†æœ‰æ•ˆæ ·æœ¬: {len(valid_set)}")      
          
    # åˆ›å»º DataLoader      
    train_loader = DataLoader(train_set, batch_size=args.batch_size, shuffle=True,      
                             collate_fn=collate_fn, num_workers=args.num_workers)      
    valid_loader = DataLoader(valid_set, batch_size=args.batch_size, shuffle=False,      
                             collate_fn=collate_fn, num_workers=args.num_workers)      
          
    # åˆå§‹åŒ–æ¨¡å‹å¹¶åŠ è½½é¢„è®­ç»ƒæƒé‡      
    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')      
    model = DTIPredictor(node_feat_size=args.node_feat_size,       
                        edge_feat_size=args.edge_feat_size,      
                        hidden_feat_size=args.hidden_feat_size,       
                        layer_num=args.layer_num).to(device)      
        
    # åŠ è½½é¢„è®­ç»ƒcheckpoint    
    logging.info(f"\nğŸ“¥ åŠ è½½é¢„è®­ç»ƒæ¨¡å‹: {args.pretrained_ckpt}")    
    model.load_state_dict(torch.load(args.pretrained_ckpt))    
    logging.info("âœ… é¢„è®­ç»ƒæ¨¡å‹åŠ è½½æˆåŠŸ!")    
        
    optimizer = optim.Adam(model.parameters(), lr=args.learning_rate,       
                          weight_decay=args.weight_decay)      
    criterion = nn.MSELoss()      
      
    logging.info(f"\nğŸš€ å¼€å§‹å¾®è°ƒè®­ç»ƒ...")  
    logging.info(f"   - å­¦ä¹ ç‡: {args.learning_rate}")  
    logging.info(f"   - æ‰¹æ¬¡å¤§å°: {args.batch_size}")  
    logging.info(f"   - æœ€å¤§è½®æ•°: {args.epochs}")  
    logging.info(f"   - æ—©åœè€å¿ƒå€¼: {args.early_stop_epoch}")  
          
    # è®­ç»ƒå¾ªç¯      
    best_valid_rmse = float('inf')      
    patience_counter = 0      
          
    model.train()      
    for epoch in range(args.epochs):      
        # è®­ç»ƒé˜¶æ®µ      
        epoch_loss = 0.0      
        for data in train_loader:      
            bg, label = data      
            bg, label = bg.to(device), label.to(device)      
                  
            pred_lp, pred_pl = model(bg)      
            loss = (criterion(pred_lp, label) + criterion(pred_pl, label) +      
                   criterion(pred_lp, pred_pl)) / 3      
                  
            optimizer.zero_grad()      
            loss.backward()      
            optimizer.step()      
                  
            epoch_loss += loss.item() * label.size(0)      
              
        epoch_loss = epoch_loss / len(train_set)      
        epoch_rmse = np.sqrt(epoch_loss)      
              
        # éªŒè¯é˜¶æ®µ      
        valid_rmse, valid_pr = val(model, valid_loader, device)      
              
        logging.info(f"Epoch {epoch}: train_loss={epoch_loss:.4f}, train_rmse={epoch_rmse:.4f}, "      
                    f"valid_rmse={valid_rmse:.4f}, valid_pr={valid_pr:.4f}")      
              
        # ä¿å­˜æœ€ä½³æ¨¡å‹      
        if valid_rmse < best_valid_rmse:      
            best_valid_rmse = valid_rmse      
            patience_counter = 0      
            torch.save(model.state_dict(), args.save_path)      
            logging.info(f"ğŸ’¾ ä¿å­˜æœ€ä½³å¾®è°ƒæ¨¡å‹ (valid_rmse={valid_rmse:.4f})")      
        else:      
                    patience_counter += 1  
                    if patience_counter >= args.early_stop_epoch:      
                        logging.info(f"â¹ï¸  Early stopping at epoch {epoch}")      
                        break      
                    
            # åŠ è½½æœ€ä½³æ¨¡å‹å¹¶æœ€ç»ˆéªŒè¯      
    logging.info(f"\nğŸ“Š åŠ è½½æœ€ä½³æ¨¡å‹è¿›è¡Œæœ€ç»ˆè¯„ä¼°...")  
    model.load_state_dict(torch.load(args.save_path))      
    final_valid_rmse, final_valid_pr = val(model, valid_loader, device)      
    logging.info(f"\nğŸ‰ æœ€ç»ˆå¾®è°ƒéªŒè¯ç»“æœ: RMSE={final_valid_rmse:.4f}, Pearson={final_valid_pr:.4f}")      

if __name__ == '__main__':      
    main()