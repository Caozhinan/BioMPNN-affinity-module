Job ID: 526522
Node: f146
Start time: Wed Oct 15 22:23:30 HKT 2025
CUDA devices: 2
Wed Oct 15 22:23:30 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 575.51.03              Driver Version: 575.51.03      CUDA Version: 12.9     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA GeForce RTX 4090        On  |   00000000:34:00.0 Off |                  Off |
| 85%   65C    P2            322W /  350W |   14927MiB /  24564MiB |    100%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA GeForce RTX 4090        On  |   00000000:35:00.0 Off |                  Off |
| 63%   54C    P2            266W /  350W |    7461MiB /  24564MiB |    100%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA GeForce RTX 4090        On  |   00000000:9C:00.0 Off |                  Off |
| 68%   49C    P8             28W /  350W |     402MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA GeForce RTX 4090        On  |   00000000:9D:00.0 Off |                  Off |
| 86%   68C    P2            330W /  350W |    8689MiB /  24564MiB |    100%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   4  NVIDIA GeForce RTX 4090        On  |   00000000:9E:00.0 Off |                  Off |
| 73%   61C    P2            206W /  350W |    8823MiB /  24564MiB |     92%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A          280871      C   ...olabfold-conda/bin/python3.10        408MiB |
|    0   N/A  N/A         2748919      C   python                                11816MiB |
|    1   N/A  N/A          280871      C   ...olabfold-conda/bin/python3.10        386MiB |
|    1   N/A  N/A          643763      C   ...olabfold-conda/bin/python3.10        434MiB |
|    2   N/A  N/A          280871      C   ...olabfold-conda/bin/python3.10        386MiB |
|    3   N/A  N/A          280871      C   ...olabfold-conda/bin/python3.10        386MiB |
|    3   N/A  N/A          641428      C   ...olabfold-conda/bin/python3.10        434MiB |
|    4   N/A  N/A          280871      C   ...olabfold-conda/bin/python3.10        386MiB |
|    4   N/A  N/A          638569      C   ...olabfold-conda/bin/python3.10        432MiB |
+-----------------------------------------------------------------------------------------+
训练集样本数: 208626
验证集样本数: 23180
成功加载训练集: 208626 个样本
成功加载验证集: 23180 个样本
Epoch 0: train_loss=407.9105, train_rmse=20.1968, valid_rmse=2.2107, valid_pr=0.1797
保存最佳模型 (valid_rmse=2.2107)
Epoch 1: train_loss=11.6182, train_rmse=3.4085, valid_rmse=1.5201, valid_pr=0.2692
保存最佳模型 (valid_rmse=1.5201)
Epoch 2: train_loss=4.0199, train_rmse=2.0050, valid_rmse=1.3440, valid_pr=0.3386
保存最佳模型 (valid_rmse=1.3440)
Epoch 3: train_loss=2.1810, train_rmse=1.4768, valid_rmse=1.2781, valid_pr=0.3795
保存最佳模型 (valid_rmse=1.2781)
Epoch 4: train_loss=1.5669, train_rmse=1.2518, valid_rmse=1.3471, valid_pr=0.3166
Epoch 5: train_loss=1.3094, train_rmse=1.1443, valid_rmse=1.2612, valid_pr=0.4063
保存最佳模型 (valid_rmse=1.2612)
Epoch 6: train_loss=1.1832, train_rmse=1.0878, valid_rmse=1.2179, valid_pr=0.4573
保存最佳模型 (valid_rmse=1.2179)
Epoch 7: train_loss=1.0904, train_rmse=1.0442, valid_rmse=1.2031, valid_pr=0.4694
保存最佳模型 (valid_rmse=1.2031)
Epoch 8: train_loss=1.0226, train_rmse=1.0112, valid_rmse=1.1990, valid_pr=0.5008
保存最佳模型 (valid_rmse=1.1990)
Epoch 9: train_loss=0.9677, train_rmse=0.9837, valid_rmse=1.1763, valid_pr=0.5123
保存最佳模型 (valid_rmse=1.1763)
Epoch 10: train_loss=0.9222, train_rmse=0.9603, valid_rmse=1.1771, valid_pr=0.5057
Epoch 11: train_loss=0.8873, train_rmse=0.9420, valid_rmse=1.2051, valid_pr=0.5530
Epoch 12: train_loss=0.8553, train_rmse=0.9248, valid_rmse=1.1296, valid_pr=0.5665
保存最佳模型 (valid_rmse=1.1296)
Epoch 13: train_loss=0.8270, train_rmse=0.9094, valid_rmse=1.1004, valid_pr=0.5967
保存最佳模型 (valid_rmse=1.1004)
Epoch 14: train_loss=0.7974, train_rmse=0.8930, valid_rmse=1.0869, valid_pr=0.6058
保存最佳模型 (valid_rmse=1.0869)
Epoch 15: train_loss=0.7753, train_rmse=0.8805, valid_rmse=1.0734, valid_pr=0.6175
保存最佳模型 (valid_rmse=1.0734)
Epoch 16: train_loss=0.7528, train_rmse=0.8676, valid_rmse=1.0994, valid_pr=0.6324
Epoch 17: train_loss=0.7326, train_rmse=0.8559, valid_rmse=1.0501, valid_pr=0.6376
保存最佳模型 (valid_rmse=1.0501)
Epoch 18: train_loss=0.7146, train_rmse=0.8453, valid_rmse=1.0504, valid_pr=0.6510
Epoch 19: train_loss=0.6962, train_rmse=0.8344, valid_rmse=1.1227, valid_pr=0.6567
Epoch 20: train_loss=0.6782, train_rmse=0.8235, valid_rmse=1.0324, valid_pr=0.6554
保存最佳模型 (valid_rmse=1.0324)
Epoch 21: train_loss=0.6638, train_rmse=0.8148, valid_rmse=1.0616, valid_pr=0.6694
Epoch 22: train_loss=0.6511, train_rmse=0.8069, valid_rmse=0.9928, valid_pr=0.6857
保存最佳模型 (valid_rmse=0.9928)
Epoch 23: train_loss=0.6369, train_rmse=0.7980, valid_rmse=1.1624, valid_pr=0.6776
Epoch 24: train_loss=0.6254, train_rmse=0.7908, valid_rmse=0.9923, valid_pr=0.6855
保存最佳模型 (valid_rmse=0.9923)
Epoch 25: train_loss=0.6141, train_rmse=0.7836, valid_rmse=0.9886, valid_pr=0.6954
保存最佳模型 (valid_rmse=0.9886)
Epoch 26: train_loss=0.6032, train_rmse=0.7767, valid_rmse=0.9752, valid_pr=0.7011
保存最佳模型 (valid_rmse=0.9752)
Epoch 27: train_loss=0.5939, train_rmse=0.7707, valid_rmse=0.9652, valid_pr=0.7062
保存最佳模型 (valid_rmse=0.9652)
Epoch 28: train_loss=0.5829, train_rmse=0.7635, valid_rmse=0.9883, valid_pr=0.7020
Epoch 29: train_loss=0.5744, train_rmse=0.7579, valid_rmse=0.9780, valid_pr=0.7012
Epoch 30: train_loss=0.5655, train_rmse=0.7520, valid_rmse=1.0096, valid_pr=0.7112
Epoch 31: train_loss=0.5577, train_rmse=0.7468, valid_rmse=0.9681, valid_pr=0.7115
Epoch 32: train_loss=0.5493, train_rmse=0.7411, valid_rmse=0.9583, valid_pr=0.7205
保存最佳模型 (valid_rmse=0.9583)
Epoch 33: train_loss=0.5404, train_rmse=0.7351, valid_rmse=0.9801, valid_pr=0.7079
Epoch 34: train_loss=0.5336, train_rmse=0.7304, valid_rmse=0.9572, valid_pr=0.7242
保存最佳模型 (valid_rmse=0.9572)
Epoch 35: train_loss=0.5277, train_rmse=0.7264, valid_rmse=0.9567, valid_pr=0.7156
保存最佳模型 (valid_rmse=0.9567)
Epoch 36: train_loss=0.5189, train_rmse=0.7204, valid_rmse=0.9483, valid_pr=0.7289
保存最佳模型 (valid_rmse=0.9483)
Epoch 37: train_loss=0.5133, train_rmse=0.7165, valid_rmse=0.9589, valid_pr=0.7225
Epoch 38: train_loss=0.5073, train_rmse=0.7123, valid_rmse=0.9487, valid_pr=0.7238
Epoch 39: train_loss=0.4995, train_rmse=0.7068, valid_rmse=1.0002, valid_pr=0.7131
Epoch 40: train_loss=0.4944, train_rmse=0.7032, valid_rmse=0.9563, valid_pr=0.7265
Epoch 41: train_loss=0.4892, train_rmse=0.6994, valid_rmse=1.0056, valid_pr=0.7306
Epoch 42: train_loss=0.4841, train_rmse=0.6958, valid_rmse=0.9588, valid_pr=0.7280
Epoch 43: train_loss=0.4765, train_rmse=0.6903, valid_rmse=0.9336, valid_pr=0.7331
保存最佳模型 (valid_rmse=0.9336)
Epoch 44: train_loss=0.4741, train_rmse=0.6886, valid_rmse=0.9402, valid_pr=0.7330
Epoch 45: train_loss=0.4677, train_rmse=0.6839, valid_rmse=0.9545, valid_pr=0.7275
Epoch 46: train_loss=0.4636, train_rmse=0.6809, valid_rmse=0.9857, valid_pr=0.7219
Epoch 47: train_loss=0.4588, train_rmse=0.6774, valid_rmse=0.9267, valid_pr=0.7380
保存最佳模型 (valid_rmse=0.9267)
Epoch 48: train_loss=0.4552, train_rmse=0.6747, valid_rmse=0.9409, valid_pr=0.7354
Epoch 49: train_loss=0.4478, train_rmse=0.6692, valid_rmse=0.9596, valid_pr=0.7370
Epoch 50: train_loss=0.4441, train_rmse=0.6664, valid_rmse=0.9816, valid_pr=0.7343
Epoch 51: train_loss=0.4395, train_rmse=0.6630, valid_rmse=0.9317, valid_pr=0.7376
Epoch 52: train_loss=0.4359, train_rmse=0.6603, valid_rmse=0.9528, valid_pr=0.7440
Epoch 53: train_loss=0.4311, train_rmse=0.6566, valid_rmse=0.9307, valid_pr=0.7429
Epoch 54: train_loss=0.4283, train_rmse=0.6544, valid_rmse=0.9463, valid_pr=0.7300
Epoch 55: train_loss=0.4241, train_rmse=0.6512, valid_rmse=0.9365, valid_pr=0.7376
Epoch 56: train_loss=0.4233, train_rmse=0.6506, valid_rmse=0.9926, valid_pr=0.7423
Epoch 57: train_loss=0.4173, train_rmse=0.6460, valid_rmse=0.9369, valid_pr=0.7403
Epoch 58: train_loss=0.4144, train_rmse=0.6437, valid_rmse=0.9406, valid_pr=0.7442
Epoch 59: train_loss=0.4102, train_rmse=0.6405, valid_rmse=0.9286, valid_pr=0.7418
Epoch 60: train_loss=0.4055, train_rmse=0.6368, valid_rmse=0.9204, valid_pr=0.7539
保存最佳模型 (valid_rmse=0.9204)
Epoch 61: train_loss=0.4034, train_rmse=0.6352, valid_rmse=0.9388, valid_pr=0.7352
Epoch 62: train_loss=0.3992, train_rmse=0.6318, valid_rmse=0.9127, valid_pr=0.7486
保存最佳模型 (valid_rmse=0.9127)
Epoch 63: train_loss=0.3969, train_rmse=0.6300, valid_rmse=0.9152, valid_pr=0.7550
Epoch 64: train_loss=0.3919, train_rmse=0.6260, valid_rmse=0.9149, valid_pr=0.7554
Epoch 65: train_loss=0.3896, train_rmse=0.6242, valid_rmse=0.9395, valid_pr=0.7409
Epoch 66: train_loss=0.3857, train_rmse=0.6210, valid_rmse=0.9273, valid_pr=0.7461
Epoch 67: train_loss=0.3851, train_rmse=0.6206, valid_rmse=0.9235, valid_pr=0.7456
Epoch 68: train_loss=0.3815, train_rmse=0.6176, valid_rmse=0.9159, valid_pr=0.7479
Epoch 69: train_loss=0.3772, train_rmse=0.6142, valid_rmse=0.9139, valid_pr=0.7498
Epoch 70: train_loss=0.3765, train_rmse=0.6136, valid_rmse=0.9732, valid_pr=0.7461
Epoch 71: train_loss=0.3733, train_rmse=0.6110, valid_rmse=0.9113, valid_pr=0.7512
保存最佳模型 (valid_rmse=0.9113)
Epoch 72: train_loss=0.3715, train_rmse=0.6095, valid_rmse=0.9555, valid_pr=0.7401
Epoch 73: train_loss=0.3689, train_rmse=0.6074, valid_rmse=0.9580, valid_pr=0.7399
Epoch 74: train_loss=0.3658, train_rmse=0.6048, valid_rmse=0.9639, valid_pr=0.7488
Epoch 75: train_loss=0.3627, train_rmse=0.6023, valid_rmse=0.9182, valid_pr=0.7518
Epoch 76: train_loss=0.3615, train_rmse=0.6013, valid_rmse=0.9470, valid_pr=0.7467
Epoch 77: train_loss=0.3580, train_rmse=0.5984, valid_rmse=0.9370, valid_pr=0.7527
Epoch 78: train_loss=0.3555, train_rmse=0.5962, valid_rmse=0.9323, valid_pr=0.7544
Epoch 79: train_loss=0.3536, train_rmse=0.5946, valid_rmse=0.9202, valid_pr=0.7512
Epoch 80: train_loss=0.3511, train_rmse=0.5925, valid_rmse=0.9421, valid_pr=0.7489
Epoch 81: train_loss=0.3484, train_rmse=0.5902, valid_rmse=0.9123, valid_pr=0.7518
Epoch 82: train_loss=0.3451, train_rmse=0.5874, valid_rmse=0.9228, valid_pr=0.7546
Epoch 83: train_loss=0.3448, train_rmse=0.5872, valid_rmse=0.8962, valid_pr=0.7614
保存最佳模型 (valid_rmse=0.8962)
Epoch 84: train_loss=0.3433, train_rmse=0.5859, valid_rmse=0.9355, valid_pr=0.7478
Epoch 85: train_loss=0.3397, train_rmse=0.5829, valid_rmse=0.8997, valid_pr=0.7653
Epoch 86: train_loss=0.3380, train_rmse=0.5813, valid_rmse=0.9167, valid_pr=0.7498
Epoch 87: train_loss=0.3367, train_rmse=0.5802, valid_rmse=0.9016, valid_pr=0.7598
Epoch 88: train_loss=0.3341, train_rmse=0.5780, valid_rmse=0.9555, valid_pr=0.7490
Epoch 89: train_loss=0.3321, train_rmse=0.5762, valid_rmse=0.9094, valid_pr=0.7559
Epoch 90: train_loss=0.3301, train_rmse=0.5745, valid_rmse=0.9018, valid_pr=0.7584
Epoch 91: train_loss=0.3289, train_rmse=0.5735, valid_rmse=0.9366, valid_pr=0.7479
Epoch 92: train_loss=0.3259, train_rmse=0.5709, valid_rmse=0.9074, valid_pr=0.7553
Epoch 93: train_loss=0.3235, train_rmse=0.5687, valid_rmse=0.9028, valid_pr=0.7564
Epoch 94: train_loss=0.3227, train_rmse=0.5681, valid_rmse=0.9041, valid_pr=0.7584
Epoch 95: train_loss=0.3214, train_rmse=0.5669, valid_rmse=0.9030, valid_pr=0.7601
Epoch 96: train_loss=0.3192, train_rmse=0.5650, valid_rmse=0.9268, valid_pr=0.7551
Epoch 97: train_loss=0.3186, train_rmse=0.5645, valid_rmse=0.9269, valid_pr=0.7534
Epoch 98: train_loss=0.3166, train_rmse=0.5627, valid_rmse=0.9225, valid_pr=0.7601
Epoch 99: train_loss=0.3137, train_rmse=0.5601, valid_rmse=0.8777, valid_pr=0.7692
保存最佳模型 (valid_rmse=0.8777)
Epoch 100: train_loss=0.3125, train_rmse=0.5590, valid_rmse=0.9024, valid_pr=0.7662
Epoch 101: train_loss=0.3122, train_rmse=0.5588, valid_rmse=0.9423, valid_pr=0.7477
Epoch 102: train_loss=0.3105, train_rmse=0.5572, valid_rmse=0.9115, valid_pr=0.7548
Epoch 103: train_loss=0.3083, train_rmse=0.5552, valid_rmse=0.8943, valid_pr=0.7639
Epoch 104: train_loss=0.3056, train_rmse=0.5528, valid_rmse=0.9283, valid_pr=0.7552
Epoch 105: train_loss=0.3044, train_rmse=0.5517, valid_rmse=0.9186, valid_pr=0.7523
Epoch 106: train_loss=0.3022, train_rmse=0.5498, valid_rmse=0.9335, valid_pr=0.7430
Epoch 107: train_loss=0.3020, train_rmse=0.5495, valid_rmse=0.9185, valid_pr=0.7537
Epoch 108: train_loss=0.3002, train_rmse=0.5479, valid_rmse=0.9600, valid_pr=0.7521
Epoch 109: train_loss=0.2982, train_rmse=0.5461, valid_rmse=0.9130, valid_pr=0.7528
Epoch 110: train_loss=0.2983, train_rmse=0.5462, valid_rmse=0.8929, valid_pr=0.7646
Epoch 111: train_loss=0.2961, train_rmse=0.5442, valid_rmse=0.9204, valid_pr=0.7556
Epoch 112: train_loss=0.2945, train_rmse=0.5427, valid_rmse=0.9561, valid_pr=0.7622
Epoch 113: train_loss=0.2926, train_rmse=0.5409, valid_rmse=0.8983, valid_pr=0.7623
Epoch 114: train_loss=0.2917, train_rmse=0.5401, valid_rmse=0.9235, valid_pr=0.7548
Epoch 115: train_loss=0.2898, train_rmse=0.5384, valid_rmse=0.9401, valid_pr=0.7509
Epoch 116: train_loss=0.2884, train_rmse=0.5370, valid_rmse=0.9154, valid_pr=0.7532
Epoch 117: train_loss=0.2885, train_rmse=0.5371, valid_rmse=0.9335, valid_pr=0.7497
Epoch 118: train_loss=0.2871, train_rmse=0.5358, valid_rmse=0.9025, valid_pr=0.7643
Epoch 119: train_loss=0.2863, train_rmse=0.5350, valid_rmse=0.9133, valid_pr=0.7580
Epoch 120: train_loss=0.2839, train_rmse=0.5328, valid_rmse=0.8739, valid_pr=0.7722
保存最佳模型 (valid_rmse=0.8739)
Epoch 121: train_loss=0.2836, train_rmse=0.5325, valid_rmse=0.9082, valid_pr=0.7644
Epoch 122: train_loss=0.2809, train_rmse=0.5300, valid_rmse=0.9001, valid_pr=0.7647
Epoch 123: train_loss=0.2800, train_rmse=0.5292, valid_rmse=0.8888, valid_pr=0.7666
Epoch 124: train_loss=0.2801, train_rmse=0.5292, valid_rmse=0.9014, valid_pr=0.7628
Epoch 125: train_loss=0.2773, train_rmse=0.5266, valid_rmse=0.9151, valid_pr=0.7576
Epoch 126: train_loss=0.2769, train_rmse=0.5262, valid_rmse=0.8973, valid_pr=0.7614
Epoch 127: train_loss=0.2746, train_rmse=0.5240, valid_rmse=0.8902, valid_pr=0.7668
Epoch 128: train_loss=0.2740, train_rmse=0.5234, valid_rmse=0.8829, valid_pr=0.7710
Epoch 129: train_loss=0.2727, train_rmse=0.5222, valid_rmse=0.8982, valid_pr=0.7604
Epoch 130: train_loss=0.2722, train_rmse=0.5217, valid_rmse=0.9220, valid_pr=0.7584
Epoch 131: train_loss=0.2707, train_rmse=0.5203, valid_rmse=0.9047, valid_pr=0.7667
Epoch 132: train_loss=0.2706, train_rmse=0.5202, valid_rmse=0.9347, valid_pr=0.7496
Epoch 133: train_loss=0.2693, train_rmse=0.5189, valid_rmse=0.8993, valid_pr=0.7685
Epoch 134: train_loss=0.2671, train_rmse=0.5168, valid_rmse=0.9441, valid_pr=0.7525
Epoch 135: train_loss=0.2678, train_rmse=0.5175, valid_rmse=0.8972, valid_pr=0.7653
Epoch 136: train_loss=0.2663, train_rmse=0.5160, valid_rmse=0.9134, valid_pr=0.7612
Epoch 137: train_loss=0.2653, train_rmse=0.5150, valid_rmse=0.9064, valid_pr=0.7619
Epoch 138: train_loss=0.2639, train_rmse=0.5137, valid_rmse=0.8988, valid_pr=0.7588
Epoch 139: train_loss=0.2632, train_rmse=0.5130, valid_rmse=0.8807, valid_pr=0.7704
Epoch 140: train_loss=0.2625, train_rmse=0.5123, valid_rmse=0.8976, valid_pr=0.7660
Epoch 141: train_loss=0.2602, train_rmse=0.5101, valid_rmse=0.9119, valid_pr=0.7639
Epoch 142: train_loss=0.2601, train_rmse=0.5100, valid_rmse=0.8776, valid_pr=0.7707
Epoch 143: train_loss=0.2589, train_rmse=0.5088, valid_rmse=0.9089, valid_pr=0.7607
Epoch 144: train_loss=0.2589, train_rmse=0.5088, valid_rmse=0.8892, valid_pr=0.7641
Epoch 145: train_loss=0.2573, train_rmse=0.5073, valid_rmse=0.9060, valid_pr=0.7682
Epoch 146: train_loss=0.2568, train_rmse=0.5067, valid_rmse=0.9547, valid_pr=0.7453
Epoch 147: train_loss=0.2544, train_rmse=0.5044, valid_rmse=0.8944, valid_pr=0.7717
Epoch 148: train_loss=0.2538, train_rmse=0.5038, valid_rmse=0.9136, valid_pr=0.7671
Epoch 149: train_loss=0.2540, train_rmse=0.5040, valid_rmse=0.8851, valid_pr=0.7703
Epoch 150: train_loss=0.2529, train_rmse=0.5029, valid_rmse=0.8842, valid_pr=0.7666
Early stopping at epoch 150

最终验证结果: RMSE=0.8739, Pearson=0.7722
End time: Thu Oct 16 18:12:06 HKT 2025
